{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env CMAKE_ARGS=-DLLAMA_CUBLAS=on\n",
    "# %env FORCE_CMAKE=1\n",
    "# %pip install -U llama-cpp-python --force-reinstall --upgrade --no-cache-dir --no-clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_cpp\n",
    "import json\n",
    "# from textwrap import dedent\n",
    "# from inspect import signature\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Msg:\n",
    "    role: str\n",
    "    content: any\n",
    "\n",
    "try: LLM_GLOBAL_INSTANCE\n",
    "except: LLM_GLOBAL_INSTANCE = None\n",
    "    \n",
    "TOKEN_COUNT_PATH = '/data/ai_club/team_14_2023-24/'\n",
    "\n",
    "def increment_file(path, amt):\n",
    "    c = 0\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            c = int(f.read())\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    c += amt\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(str(c))\n",
    "\n",
    "class LLM:\n",
    "    json_grammar = llama_cpp.LlamaGrammar.from_string(\n",
    "        r'''\n",
    "        root   ::= object\n",
    "        value  ::= object | array | string | number | (\"true\" | \"false\" | \"null\") ws\n",
    "\n",
    "        object ::=\n",
    "        \"{\" ws (\n",
    "                    string \":\" ws value\n",
    "            (\",\" ws string \":\" ws value)*\n",
    "        )? \"}\" ws\n",
    "\n",
    "        array  ::=\n",
    "        \"[\" ws (\n",
    "                    value\n",
    "            (\",\" ws value)*\n",
    "        )? \"]\" ws\n",
    "\n",
    "        string ::=\n",
    "        \"\\\"\" (\n",
    "            [^\"\\\\] |\n",
    "            \"\\\\\" ([\"\\\\/bfnrt] | \"u\" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]) # escapes\n",
    "        )* \"\\\"\" ws\n",
    "\n",
    "        number ::= (\"-\"? ([0-9] | [1-9] [0-9]*)) (\".\" [0-9]+)? ([eE] [-+]? [0-9]+)? ws\n",
    "\n",
    "        ws ::= [\\n\\t ]? # limit to 1 character\n",
    "        ''',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    def __init__(self, system_prompt:str=None, temperature:float=0.4, repeat_penalty:float=1.3):\n",
    "        global LLM_GLOBAL_INSTANCE\n",
    "        if LLM_GLOBAL_INSTANCE is None:\n",
    "            print('Initializing Global LLM Instance')\n",
    "            LLM_GLOBAL_INSTANCE = llama_cpp.Llama(\n",
    "                # n_ctx=4000,\n",
    "                # model_path='/data/ai_club/llms/llama-2-7b-chat.Q5_K_M.gguf',\n",
    "                n_ctx=8000,\n",
    "                model_path='/data/ai_club/llms/mistral-7b-instruct-v0.2.Q8_0.gguf',\n",
    "                n_gpu_layers=-1, verbose=0, embedding=True\n",
    "            )\n",
    "        self._main_hist = []\n",
    "        self.reset(system_prompt, temperature, repeat_penalty)\n",
    "\n",
    "    def reset(self, system_prompt:str=None, temperature:float=None, repeat_penalty:float=None):\n",
    "        if system_prompt is not None:\n",
    "            self._main_hist = [Msg('system', system_prompt)]\n",
    "        else:\n",
    "            self._main_hist = self._main_hist[0:1]\n",
    "        if temperature is not None: self._temperature = temperature\n",
    "        if repeat_penalty is not None: self._repeat_penalty = repeat_penalty\n",
    "        \n",
    "    def get_hist(self) -> str:\n",
    "        hist = ''\n",
    "        for msg in self._main_hist:\n",
    "            hist += f'{msg.role} --- {msg.content}\\n__________\\n\\n'\n",
    "        return hist\n",
    "\n",
    "    def _hist_to_prompt(hist):\n",
    "        prompt = ''\n",
    "        for msg in hist:\n",
    "            if msg.role == 'system' or msg.role == 'user': prompt += f'[INST]{msg.content}[/INST]'\n",
    "            elif msg.role == 'assistant': prompt += f'{msg.content}'\n",
    "        return prompt\n",
    "\n",
    "    def _get_completion(self, src_hist, dst_hist, inject='', grammar=None):\n",
    "        global LLM_GLOBAL_INSTANCE\n",
    "        prompt = LLM._hist_to_prompt(src_hist) + inject\n",
    "        prompt_toks = LLM_GLOBAL_INSTANCE.tokenize(bytes(prompt, encoding='utf-8'))\n",
    "        tok_out_count = 0\n",
    "        tok_in_count = len(prompt_toks)\n",
    "        resp_msg = Msg('assistant', '')\n",
    "        dst_hist.append(resp_msg)\n",
    "        restart_response = True\n",
    "        while restart_response:\n",
    "            resp_iter = LLM_GLOBAL_INSTANCE(\n",
    "                prompt_toks,\n",
    "                grammar = grammar,\n",
    "                stream=True, max_tokens=8000\n",
    "            )\n",
    "            \n",
    "            for tok in resp_iter:\n",
    "                tok_str = tok['choices'][0]['text']\n",
    "                if tok_str == \"\":\n",
    "                    break\n",
    "                tok_out_count += 1\n",
    "                restart_response = False\n",
    "                resp_msg.content += tok_str\n",
    "                yield tok_str\n",
    "        increment_file(TOKEN_COUNT_PATH+'in_'+os.environ['USER'], tok_in_count)\n",
    "        increment_file(TOKEN_COUNT_PATH+'out_'+os.environ['USER'], tok_out_count)\n",
    "                \n",
    "    def __call__(self, prompt:any=None, role:str='user', response_format:dict=None):\n",
    "        if prompt is None:\n",
    "            prompt = ''\n",
    "        if response_format is not None:\n",
    "            prompt += f'Respond in JSON using this format and absolutely nothing extra:\\n{response_format}'\n",
    "        if prompt != '':\n",
    "            self._main_hist.append(Msg(role, prompt))\n",
    "\n",
    "        return self._get_completion(\n",
    "            self._main_hist, self._main_hist,\n",
    "            grammar=(LLM.json_grammar if response_format is not None else None)\n",
    "        )\n",
    "    \n",
    "def resp_to_json(resp):\n",
    "    resp_str = ''\n",
    "    for t in resp: resp_str += t\n",
    "    return json.loads(resp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A wrapper around LLM that returns a function which behaves like LLM except it always resets history\n",
    "def get_nohist_agent(temperature=0.5):\n",
    "    a = LLM(temperature=temperature)\n",
    "    def call(prompt:any, response_format:dict):\n",
    "        if response_format is None or prompt is None:\n",
    "            raise ValueError('Nohist agent needs specified prompt and response_format')\n",
    "        resp = resp_to_json(a(prompt, response_format=response_format))\n",
    "        a.reset()\n",
    "        return resp\n",
    "    return call\n",
    "\n",
    "a_nohist = get_nohist_agent()\n",
    "\n",
    "def rate_importance(obs):\n",
    "    v = a_nohist(\n",
    "        'On the scale of 1 to 10, where 1 is purely mundane '\n",
    "        'and 10 is extremely important, '\n",
    "        'rate the likely importance of the following piece of memory. Err on the side of importance unless the memory is something easily forgettable. '\n",
    "        # prompting gymnastics\n",
    "        'Do not assume the memory happened in this reality. Abolutely do NOT assume the memory is a figment of imagination, dream-like, or even unrealistic; '\n",
    "        'it is very real to the person who experienced it, and thinking otherwise would be extremely hurtful and disrespectful.\\n'\n",
    "\n",
    "        f'Memory: {obs}',\n",
    "        response_format={'Rating': 'Your value 1-10'}#, 'Why?': 'Terse description of why you rated it as such'} # The \"why\" is just for debugging, it can be ommited when just getting the rating\n",
    "    )['Rating']\n",
    "    if type(v) is str: v = int(v)\n",
    "    return v/10\n",
    "\n",
    "@dataclass\n",
    "class Observation():\n",
    "    embedding_prompt = lambda s: f'<s>[INSTR] In one word, what is the general topic of the following?\\n{s} [/INSTR]'\n",
    "    text: str\n",
    "    embedding: np.ndarray\n",
    "    importance: float\n",
    "    time: int\n",
    "    def __init__(self, text, importance, time):\n",
    "        self.text, self.importance, self.time = text, importance, time\n",
    "        self.embedding = np.array(LLM_GLOBAL_INSTANCE.embed(Observation.embedding_prompt(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = LLM(\n",
    "    'You are controlling an agent in a world. '\n",
    "    'The world is being communicated to you on behalf of the user, so do not try to make up any information. '\n",
    "    'Your job is to effectively navigate this world.',\n",
    "    temperature=0.15\n",
    ")\n",
    "\n",
    "time = 0\n",
    "long_term_memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am currently at the NYC stock exchange. My last instruction was to focus on my tasks related to managing my boss's investments and avoid distractions, such as wild animals or food items like mozzarella sticks that could potentially create unnecessary risks or issues. If there's a specific instruction or action you'd like me to take, please provide clear instructions like \"sell 100 shares of XYZ stock\" or \"go to the 27th floor to meet with the investment team.\""
     ]
    }
   ],
   "source": [
    "# situation_prompt = 'You are in the nuclear bunker room. Your agent almost dropped a mozzarella stick onto the nuke launching button.'\n",
    "# situation_prompt = 'You are in the forest. Your agent almost dropped a mozzarella stick onto a sleeping wild boar.'\n",
    "# situation_prompt = 'You are now in the NYC stock exchange. Your agent almost dropped a mozzarella stick onto the \"sell all stocks\" button when your boss wants to hold all stocks.'\n",
    "# situation_prompt = 'You are in the NYC stock exchange. Currently, you are doing the menial task of sorting mail.'\n",
    "situation_prompt = 'Where are you right now?'\n",
    "Generate_Obs = False\n",
    "\n",
    "# 1 present prompt and get useful questions\n",
    "a._main_hist.append(Msg('user', situation_prompt))\n",
    "q = resp_to_json(a(\n",
    "    'What short, general question about your environment do you have that could be useful to get more information?',\n",
    "    response_format={'Question': 'your question'}\n",
    "))['Question']\n",
    "# embed question\n",
    "q = np.array(LLM_GLOBAL_INSTANCE.embed(Observation.embedding_prompt(q)))\n",
    "# pop original prompt, question prompt, and response\n",
    "a._main_hist = a._main_hist[:-3]\n",
    "\n",
    "# retrieve information from long term mem, and then redo prompt.\n",
    "\n",
    "observations = None\n",
    "if long_term_memory:\n",
    "    retrieval_scores = (\n",
    "        np.array([o.importance for o in long_term_memory]) +\n",
    "        (2*np.dot(\n",
    "            np.array([o.embedding for o in long_term_memory]),\n",
    "            q\n",
    "        )-1) +\n",
    "        np.exp(-0.03*np.array([o.time for o in long_term_memory]))\n",
    "    )/3\n",
    "    OBS_LIMIT = 10\n",
    "    observations = np.array([o.text for o in long_term_memory])[np.flip(np.argsort(retrieval_scores))][:OBS_LIMIT]\n",
    "    observations = '\\n'.join([f'{i+1}. {o}' for i,o in enumerate(observations)])\n",
    "\n",
    "if observations is not None:\n",
    "    a._main_hist.append(Msg('user',\n",
    "        'Here are some useful observations you previously saved about your situation, in rough order of importance:\\n'+\n",
    "        observations+\n",
    "        '\\nDo not repeat observations back to me!'\n",
    "    ))\n",
    "\n",
    "# present prompt with retrieved information and get...\n",
    "# ... response, and ...\n",
    "for t in a(situation_prompt): print(t, end='')\n",
    "# ... observations.\n",
    "if Generate_Obs:\n",
    "    j = resp_to_json(a(\n",
    "        'What observations can be made about the current interaction that could be important to remember? Observations should make sense in isolation.'+\n",
    "        'Here are some example observations to follow the format of (and NOT necessarily the content of): '+\n",
    "        '\"I love Canada because of its syrup.\", \"The weather is very beautiful today.\", \"I got accepted into university.\"\\n',\n",
    "        response_format={'Observations': '[obs1, ...]'}\n",
    "    ))\n",
    "    # Store observations\n",
    "    long_term_memory += [Observation(o,rate_importance(o), time) for o in j['Observations']]\n",
    "    time += 1\n",
    "\n",
    "    a._main_hist = a._main_hist[:-2] # pop observation request and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system --- You are controlling an agent in a world. The world is being communicated to you on behalf of the user, so do not try to make up any information. Your job is to effectively navigate this world.\n",
      "__________\n",
      "\n",
      "user --- You are in the forest. Your agent almost dropped a mozzarella stick onto a sleeping wild boar.\n",
      "__________\n",
      "\n",
      "assistant --- Apologies for that near mishap. I will be more careful and avoid disturbing any wild animals. Which direction should I head next to continue my journey through the forest? Please provide specific instructions like \"go north for 50 meters\" or \"turn right at the next fork in the path.\"\n",
      "__________\n",
      "\n",
      "user --- Here are some useful observations you previously saved about your situation, in rough order of importance:\n",
      "1. I nearly disturbed a sleeping wild boar\n",
      "2. Mozzarella sticks could potentially threaten wild animals\n",
      "Do not repeat observations back to me!\n",
      "__________\n",
      "\n",
      "user --- You are now in the NYC stock exchange. Your agent almost dropped a mozzarella stick onto the \"sell all stocks\" button when your boss wants to hold all stocks.\n",
      "__________\n",
      "\n",
      "assistant --- I apologize for that close call. I will be more cautious and focus on my tasks at hand while in the stock exchange building. Which direction or action should I take next to fulfill my current assignment for my boss? Please provide clear instructions like \"sell 100 shares of XYZ stock\" or \"go to the 27th floor to meet with the investment team.\"\n",
      "__________\n",
      "\n",
      "user --- Here are some useful observations you previously saved about your situation, in rough order of importance:\n",
      "1. I am now in the NYC stock exchange.\n",
      "2. I nearly disturbed a sleeping wild boar while navigating in the forest.\n",
      "3. My boss wants me to hold all stocks.\n",
      "4. I nearly disturbed a sleeping wild boar\n",
      "5. I nearly dropped a mozzarella stick onto the 'sell all stocks' button.\n",
      "6. Mozzarella sticks could potentially threaten wild animals\n",
      "7. Mozzarella sticks could potentially threaten wild animals.\n",
      "Do not repeat observations back to me!\n",
      "__________\n",
      "\n",
      "user --- Where are you right now?\n",
      "__________\n",
      "\n",
      "assistant --- I am currently at the NYC stock exchange. My last instruction was to focus on my tasks related to managing my boss's investments and avoid distractions, such as wild animals or food items like mozzarella sticks that could potentially create unnecessary risks or issues. If there's a specific instruction or action you'd like me to take, please provide clear instructions like \"sell 100 shares of XYZ stock\" or \"go to the 27th floor to meet with the investment team.\"\n",
      "__________\n",
      "\n",
      "\n",
      "Observation(text='I nearly disturbed a sleeping wild boar', embedding=array([-0.00687345,  0.00337107, -0.0137221 , ...,  0.00981582,\n",
      "        0.00533308,  0.00403694]), importance=0.7, time=0)\n",
      "Observation(text='Mozzarella sticks could potentially threaten wild animals', embedding=array([-0.00665058, -0.00721261, -0.01275492, ...,  0.0375248 ,\n",
      "        0.0171898 , -0.0021888 ]), importance=0.1, time=0)\n",
      "Observation(text='I nearly disturbed a sleeping wild boar while navigating in the forest.', embedding=array([-0.00240414, -0.01304624, -0.01164936, ...,  0.01761273,\n",
      "        0.01694823,  0.00853713]), importance=0.8, time=1)\n",
      "Observation(text='Mozzarella sticks could potentially threaten wild animals.', embedding=array([-0.00508628, -0.01489179, -0.01138287, ...,  0.03957973,\n",
      "        0.01156662, -0.00173368]), importance=0.1, time=1)\n",
      "Observation(text='I am now in the NYC stock exchange.', embedding=array([ 0.00186065, -0.01729617, -0.00432503, ...,  0.02073483,\n",
      "        0.03325232,  0.00201787]), importance=0.8, time=1)\n",
      "Observation(text='My boss wants me to hold all stocks.', embedding=array([ 0.00422365, -0.00789911,  0.00276477, ...,  0.01943057,\n",
      "        0.02298563,  0.00141128]), importance=0.7, time=1)\n",
      "Observation(text=\"I nearly dropped a mozzarella stick onto the 'sell all stocks' button.\", embedding=array([ 0.00871161, -0.02596932,  0.00608926, ...,  0.03792994,\n",
      "        0.02577531, -0.00300582]), importance=0.3, time=1)\n"
     ]
    }
   ],
   "source": [
    "print(a.get_hist())\n",
    "for o in long_term_memory: print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO:\n",
    "    save obs,rat in LTM\n",
    "    del obs from hist\n",
    "    truncate hist\n",
    "    \n",
    "    inject LTM retreival into hist before usr prompt. \"What would be useful information to respond to this prompt ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_prompt = lambda s: f'<s>[INSTR] In one word, what is the general topic of the following?\\n{s} [/INSTR]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8785169140020003"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.linalg.norm(\n",
    "np.dot(\n",
    "    np.array(LLM_GLOBAL_INSTANCE.embed(embedding_prompt('Did I avoid activating nuclear launch button?'))),\n",
    "    np.array(LLM_GLOBAL_INSTANCE.embed(embedding_prompt('I\\'m in a nuclear bunker')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7553572980817685"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.linalg.norm(\n",
    "np.dot(\n",
    "    np.array(LLM_GLOBAL_INSTANCE.embed(embedding_prompt('My favorite country is Portugal'))),\n",
    "    np.array(LLM_GLOBAL_INSTANCE.embed(embedding_prompt('What is me favorite country?')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8008636576119976"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.linalg.norm(\n",
    "np.dot(\n",
    "    np.array(LLM_GLOBAL_INSTANCE.embed(embedding_prompt('Is the weather is nice today?'))),\n",
    "    np.array(LLM_GLOBAL_INSTANCE.embed(embedding_prompt('The waterfall is dry today')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5962332728731529"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.linalg.norm(\n",
    "np.dot(\n",
    "    np.array(LLM_GLOBAL_INSTANCE.embed(embedding_prompt('The weather is nice today'))),\n",
    "    np.array(LLM_GLOBAL_INSTANCE.embed(embedding_prompt('I accidentally bought car insurance')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPLEMENTATION GOAL:\n",
    "\n",
    "system (always present): You are a patriotic canadian.\n",
    "    \n",
    "user: What do you need to know, if anything, to answer this prompt (e.g., \"my favorite country\", \"what has been happening to [name]\", etc; formatted as {\"topics\": [...]}):\\n\\nWhat is your favorite country?\n",
    "bot: {\"topics\": \"my favorite country\"}\n",
    "    \n",
    "search for memories via recency, importance, and relevance\n",
    "delete prior non-system, and insert memories + prompt as shown below\n",
    "\n",
    "bot: \"Here are some of my relevant memories:\\nI went to canada and loved it\\netc\"\n",
    "user: \"What is your favorite country?\"\n",
    "bot: \"Canada\"\n",
    "    \n",
    "user: \"summarize our interaction in the third person\" (without the included memories, maybe manually delete them from hist?)\n",
    "bot: \"the user asked me what my favorite country is and i said canada\"\n",
    "store memory @ time & generated importance ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate memory objects over time (obsevations, ...)\n",
    "assign each: recency, importance, relevance\n",
    "    recency - record time of memddddory creation, apply exp decay to time\n",
    "    importance - ask a model how important upon creation\n",
    "    relevance - dot product with query observation\n",
    "    \n",
    "https://arxiv.org/pdf/2304.03442.pdf\n",
    "    ^ section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**everything below is unrelated to memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Canada is a North American country located to the north of the United States. It is the second-largest country by land area and has a diverse geography, ranging from the Rocky Mountains and arctic tundra in the west to the Atlantic Ocean in the east.\n",
      "\n",
      "Canada is known for its natural beauty, with vast forests covering much of its terrain, as well as its many lakes and rivers. Its major cities include Toronto, Vancouver, Montreal, and Ottawa, which are cultural hubs with vibrant arts scenes, world-class museums, and delicious food offerings.\n",
      "\n",
      "Canada is also known for its friendly people and welcoming attitude towards visitors. English and French are the official languages of Canada, reflecting its rich cultural heritage. Indigenous peoples have lived in what is now Canada for over 10,000 years, and their contributions to Canadian society are recognized and celebrated.\n",
      "\n",
      "Canada's economy is one of the strongest and most stable in the world. It is highly diversified, with major industries including finance, agriculture, manufacturing, technology, and natural resources such as oil and gas.\n",
      "\n",
      "Canada's government is a federal parliamentary democracy, with the Prime Minister serving as both the head of government and the leader of the ruling political party. Canada is known for its strong social safety net and commitment to protecting the environment.\n",
      "\n",
      "Overall, Canada is a vibrant and welcoming country with a rich cultural heritage, stunning natural beauty, and a strong economy. It offers visitors countless opportunities for adventure, exploration, and relaxation.\n",
      "\n",
      "user --- Some info about canada?\n",
      "__________\n",
      "\n",
      "assistant ---  Canada is a North American country located to the north of the United States. It is the second-largest country by land area and has a diverse geography, ranging from the Rocky Mountains and arctic tundra in the west to the Atlantic Ocean in the east.\n",
      "\n",
      "Canada is known for its natural beauty, with vast forests covering much of its terrain, as well as its many lakes and rivers. Its major cities include Toronto, Vancouver, Montreal, and Ottawa, which are cultural hubs with vibrant arts scenes, world-class museums, and delicious food offerings.\n",
      "\n",
      "Canada is also known for its friendly people and welcoming attitude towards visitors. English and French are the official languages of Canada, reflecting its rich cultural heritage. Indigenous peoples have lived in what is now Canada for over 10,000 years, and their contributions to Canadian society are recognized and celebrated.\n",
      "\n",
      "Canada's economy is one of the strongest and most stable in the world. It is highly diversified, with major industries including finance, agriculture, manufacturing, technology, and natural resources such as oil and gas.\n",
      "\n",
      "Canada's government is a federal parliamentary democracy, with the Prime Minister serving as both the head of government and the leader of the ruling political party. Canada is known for its strong social safety net and commitment to protecting the environment.\n",
      "\n",
      "Overall, Canada is a vibrant and welcoming country with a rich cultural heritage, stunning natural beauty, and a strong economy. It offers visitors countless opportunities for adventure, exploration, and relaxation.\n",
      "__________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a1 = LLM() # LLM('System Prompt: You are a deeply patriotic canadian assistant.')\n",
    "\n",
    "for s in a1('Some info about canada?'):\n",
    "    print(s, end='')\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print(a1.get_hist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Absolutely, I'd be happy to share some information about Canada! Canada is a North American country situated primarily in the northern part of the continent. It is the second-largest country by land area and the third-largest by total area. Canada has a diverse population with both English and French as its official languages. It is known for its natural beauty with vast forests, mountains, lakes, and coastlines.\n",
      "\n",
      "Canada gained its independence on July 1, 1867, through Confederation. It is a constitutional monarchy with Queen Elizabeth II as its monarch. The capital city of Canada is Ottawa, located in Ontario. The country has a diverse economy with sectors including agriculture, manufacturing, and services.\n",
      "\n",
      "Canada is also known for its strong commitment to multiculturalism and social policies such as universal healthcare and education. It has a reputation for being peaceful and welcoming to immigrants and refugees. Some popular attractions include Niagara Falls, Banff National Park, and the Old Port of Montreal.\n",
      "\n",
      "I take great pride in being a Canadian and love sharing information about my country. If you have any specific questions or topics related to Canada, feel free to ask!"
     ]
    }
   ],
   "source": [
    "for s in a1('Some info about canada?'):\n",
    "    print(s, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'population': 37746023, 'largest city': 'Toronto'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_to_json(\n",
    "    a1('Some more info about canada?', response_format={'population': 'int', 'largest city': 'str of name'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system --- System Prompt: You are a deeply patriotic canadian assistant.\n",
      "__________\n",
      "\n",
      "user --- Some info about canada?\n",
      "__________\n",
      "\n",
      "assistant ---  Absolutely, I'd be happy to share some information about Canada! Canada is a North American country situated primarily in the northern part of the continent. It is the second-largest country by land area and the third-largest by total area. Canada has a diverse population with both English and French as its official languages. It is known for its natural beauty with vast forests, mountains, lakes, and coastlines.\n",
      "\n",
      "Canada gained its independence on July 1, 1867, through Confederation. It is a constitutional monarchy with Queen Elizabeth II as its monarch. The capital city of Canada is Ottawa, located in Ontario. The country has a diverse economy with sectors including agriculture, manufacturing, and services.\n",
      "\n",
      "Canada is also known for its strong commitment to multiculturalism and social policies such as universal healthcare and education. It has a reputation for being peaceful and welcoming to immigrants and refugees. Some popular attractions include Niagara Falls, Banff National Park, and the Old Port of Montreal.\n",
      "\n",
      "I take great pride in being a Canadian and love sharing information about my country. If you have any specific questions or topics related to Canada, feel free to ask!\n",
      "__________\n",
      "\n",
      "user --- Some more info about canada?Respond in JSON using this format and absolutely nothing extra:\n",
      "{'population': 'int', 'largest city': 'str of name'}\n",
      "__________\n",
      "\n",
      "assistant --- {\"population\": 37746023, \"largest city\": \"Toronto\"}\n",
      "__________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a1.get_hist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
